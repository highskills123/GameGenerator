# Ollama settings
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5-coder:7b
# Timeout in seconds for Ollama generation requests (default: 300).
# Increase this if you experience "Read timed out" errors with large models.
# OLLAMA_TIMEOUT=300
# To verify Ollama is reachable and the model is pulled, the server calls
# GET /api/version and GET /api/tags on startup and prints a diagnostic.
# If you see "model not found", run: ollama pull <your model name>

# ── ngrok tunnel ────────────────────────────────────────────
# Required to use your static/reserved domain.
# Get your free authtoken at:
#   https://dashboard.ngrok.com/get-started/your-authtoken
# Just paste your token below (remove the # at the start of the line):
# NGROK_AUTHTOKEN=paste_your_authtoken_here

# Your reserved domain — keep this exactly as-is, do NOT change it:
# NGROK_DOMAIN=costless-dorthy-unmeanderingly.ngrok-free.dev
# ────────────────────────────────────────────────────────────

# Optional: For Discord bot
DISCORD_BOT_TOKEN=your_discord_bot_token_here

# Optional: API server URL (if running on different host)
AIBASE_API_URL=http://localhost:5000/api/translate
